{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62ae2df3",
   "metadata": {},
   "source": [
    "# Unsupervised Learning Example - Folktale Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c9f678",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486c9660",
   "metadata": {},
   "source": [
    "## Load and Clean the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d08986",
   "metadata": {},
   "source": [
    "This is the folktales dataset from the Miltilingual Folktales Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a8b248",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_text_file = '../data/folktales.csv'\n",
    "\n",
    "data = pd.read_csv(example_text_file)\n",
    "\n",
    "data[\"Index\"]=data.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314faff3",
   "metadata": {},
   "source": [
    "Here we have only decided to do a limited cleaning on the data to assist in our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1205760c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send to Lowercase\n",
    "data['Story'] = data['Story'].apply(lambda x: \" \".join(x.lower() for x in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66984778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Punctuation\n",
    "data['Story'] = data['Story'].str.replace('[^\\w\\s]','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07d951e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Story'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defd2f8a",
   "metadata": {},
   "source": [
    "## Using TF-IDF with K-Means Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4249f5d4",
   "metadata": {},
   "source": [
    "This takes the TF-IDF matrix and applies a [k-means clustering algorithm](https://en.wikipedia.org/wiki/K-means_clustering). This groups the texts into clusters of similar terms from the TF-IDF matrix. This algorithm randomly seeds X \"means\", the values are then clustered into the nearest mean. The centroid of the values in each cluster then becomes the new mean and the process repeats until a convergence is reached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa969721",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = 30\n",
    "\n",
    "num_clusters = groups\n",
    "num_seeds = groups\n",
    "max_iterations = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd6149d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_num_components = 2\n",
    "tsne_num_components = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05c14a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = matplotlib.cm.get_cmap(\"nipy_spectral\", groups) # Builds a discrete color mapping using a built in matplotlib color map\n",
    "\n",
    "c = {}\n",
    "for i in range(cmap.N): # Converts our discrete map into Hex Values\n",
    "    rgba = cmap(i)\n",
    "    c.update({i:matplotlib.colors.rgb2hex(rgba)})\n",
    "\n",
    "labels_color_map=c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3c10c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate tf-idf of texts\n",
    "tfidf = TfidfVectorizer(max_features=1000, lowercase=True, analyzer='word',stop_words= 'english',ngram_range=(1,1))\n",
    "tf_idf_matrix = tfidf.fit_transform(data['Story'])\n",
    "\n",
    "# create k-means model with custom config\n",
    "clustering_model = KMeans(\n",
    "    n_clusters=num_clusters,\n",
    "    max_iter=max_iterations#,\n",
    "    #precompute_distances=\"auto\",\n",
    "    #n_jobs=-1\n",
    ")\n",
    "\n",
    "labels = clustering_model.fit_predict(tf_idf_matrix)\n",
    "#print(labels)\n",
    "\n",
    "X = tf_idf_matrix.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc9f83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_data = PCA(n_components=pca_num_components).fit_transform(X)\n",
    "print(reduced_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda91fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "legendlist=[mpatches.Patch(color=labels_color_map[key],label=str(key))for key in labels_color_map.keys()]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for index, instance in enumerate(reduced_data):\n",
    "    #print(instance, index, labels[index])\n",
    "    pca_comp_1, pca_comp_2 = reduced_data[index]\n",
    "    color = labels_color_map[labels[index]]\n",
    "    ax.scatter(pca_comp_1, pca_comp_2, c=color)\n",
    "if groups<=10:\n",
    "    plt.legend(handles=legendlist)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857cc678",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_groups = np.transpose([labels,data['Title'],data['Author'],data['Index']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a4f0f3",
   "metadata": {},
   "source": [
    "These are the titles of the texts in each cluster. Keep in mind that each time you run the algorithm, the randomness in generating the initial means will result in different clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c3abec",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(title_groups)):\n",
    "    data.loc[i,'Group'] = title_groups[i][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fde2df2",
   "metadata": {},
   "source": [
    "This is how the groups break down by number of texts in each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e859fd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_counts = data['Group'].value_counts()\n",
    "ss = min(g_counts)\n",
    "#g_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bc8788",
   "metadata": {},
   "source": [
    "Here we can look at a sample of the titles in a particular group and the TF-IDF data for that group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc24eb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "grp=1\n",
    "data[data['Group']==grp]['Title']#.sample(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ce404d",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_ids = list(data[data['Group']==grp]['Index'])\n",
    "group_tfidf = data[data['Index'].isin(group_ids)]['Story'].apply(lambda x: pd.value_counts(x.split(\" \"))).sum(axis = 0).reset_index()\n",
    "\n",
    "group_tfidf.columns = ['words','tf']\n",
    "group_tfidf.sort_values(by='tf', ascending=False)[:10]\n",
    "\n",
    "for i,word in enumerate(group_tfidf['words']):\n",
    "    group_tfidf.loc[i, 'idf'] = np.log(data.shape[0]/(len(data[data['Story'].str.contains(word)])))\n",
    "\n",
    "group_tfidf['tfidf'] = group_tfidf['tf'] * group_tfidf['idf']\n",
    "group_tfidf.sort_values(by='tfidf', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865272b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_index = 1\n",
    "pd.Series(' '.join(data[data['Index']==text_index]['Story']).split()).value_counts()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9463bf",
   "metadata": {},
   "source": [
    "Here we can look at all the groups along with the authors and the index for each story."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3890d78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(groups):\n",
    "    print(\"\")\n",
    "    print(\"#### {} ###\".format(i))\n",
    "    print(\"\")\n",
    "    for el in title_groups:\n",
    "        if el[0]==i:\n",
    "            print(\"{} --- {} --- #{}\".format(el[1],str(el[2]).strip(), el[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3704c2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
